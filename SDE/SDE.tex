%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Author: Vignesh Iyer                                 %
% MS CSE ASU                                           %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% -------------- README --------------
% Visit https://github.com/vgnshiyer/ASU-sparkysundevil-resume-template for comprehensive documenation.

% -------------- Resume ---------------
\documentclass{resume}
\usepackage{amsmath}
\begin{document}

% --------- Contact Information -----------
\introduction[
    fullname={Amogh Jagadish Tambad},
    location={San Francisco, CA},
    email={tambadamogh@gmail.com},
    phone={(480) 876-5096},
    linkedin={linkedin.com/in/ajtambad},
    github={github.com/Ajtambad}
]

% --------- Education ---------
\begin{educationSection}{Education}
    \educationItem[
        university={Arizona State University, Tempe, AZ},
        graduation={May 2025},
        grade={4.00 GPA},
        program={Master of Science, Computer Science},
        coursework={Cloud Computing, Data Processing at Scale, Data Mining, Software Security},
    ] % ASU

    \educationItem[
        university={REVA University, Bangalore, KA},
        graduation={May 2021},
        grade={3.77 GPA},
        program={Bachelor of Technology, Computer Science},
        coursework={Data Structure and Algorithms, Operating Systems, Cloud Computing, Computer Networks},
    ]
\end{educationSection}
% --------- Skills -----------
\begin{skillsSection}{Skills}
    \skillItem[
        category={Languages},
        skills={Python, C++ Go, Java, JavaScript, Typescript, Scala, HTML, XML}
    ] \\
    \skillItem[
        category={Technologies},
        skills={AWS (EC2, Lambda, S3, ECS, CloudFormation, EKS, ECR), Pandas, Numpy, Spark, Docker, Kubernetes, React, Angular, Flask, Node.js, Terraform, Jenkins}
    ] \\
    \skillItem[
        category={Database Systems},
        skills={SQL(MySQL, PostgreSQL), NoSQL (MongoDB)}
    ] \\
    \skillItem[
        category={Tools},
        skills={Linux, Git (Version Control), Github, Nginx, Kafka, Redis, Prometheus, Postman, Cursor, CoPilot, Claude Code}
    ] \\
    \skillItem[
        category={LLM/GenAI Frameworks},
        skills={MCP, LangChain, LangGraph, RAG, VectorDBs (FAISS, ChromaDB)}
    ] \\
    \skillItem[
        category={Miscellaneous},
        skills={Distributed Systems, RESTful APIs, Microservices, Object-Oriented Programming, Agile, Test Driven Development (TDD), Infrastructure-as-code, Machine Learning, Web Services}
    ]
\end{skillsSection}

% --------- Experience -----------

    \begin{experienceSection}{Professional Experience}
    % \experienceItem[
    %     company={Arizona State University},
    %     location={Remote},
    %     position={Research Assistant, VISA Lab},
    %     duration={Jun 2025 - Present}
    % ]
    % \begin{itemize}
    %     \itemsep -6pt {}
    %     \item Developed \textbf{FlowBench}, a workflow-based distributed benchmark by leveraging \textbf{Python}, \textbf{Docker}, \textbf{Kubernetes}, and FaaS principles to evaluate custom edge computing applications, providing a comprehensive report on 6+ metrics.
    %     \item Built and tested a video analytics workflow via \textbf{OpenCV} on a containerized microservices architecture with Kubernetes, processing 10,000+ frames per minute.
    % \end{itemize}


    \experienceItem[
        company={Arch Mortgage Insurance},
        location={Greensboro, NC},
        position={Software Engineer Intern},
        duration={Jun 2024 - Aug 2024}
    ]
    \begin{itemize}
        \itemsep -6pt {}
        \item Built a \textbf{JavaScript} and \textbf{Cribl Stream} based scalable data processing solution and created 10+ conditional pipelines for log filtering and transformation, implementing custom business logic to filter and route logs from \textbf{OpenShift} pods to Splunk
        \item Engineered a container image synchronization system through \textbf{Ansible} automation scripts and \textbf{Red Hat registry} APIs that integrates with \textbf{Nexus Repository} for artifact management, eliminating 90\% of manual update processes
        
    \end{itemize}

    \experienceItem[
        company={Cerner Healthcare},
        location={Bangalore, KA},
        position={Software Engineer},
        duration={May 2021 - Jul 2023}
    ]
    \begin{itemize}
        \itemsep -6pt {}
        \item Designed cloud migration scripts and data transformation pipelines to migrate 80\% of enterprise data from on-premises infrastructure to AWS, thereby enhancing access flexibility, security, and cost-efficiency
        \item Automated the monitoring and alerting systems with \textbf{Zabbix} and \textbf{Splunk} APIs, developing custom dashboards and incident response automation that sped production resolution by 30\%
        \item Troubleshot and resolved \textbf{Jenkins} pipeline issues, minimizing support ticket resolution time by \textbf{40\%} and ensuring \textbf{99.9\%} uptime for \textbf{CI/CD} workflows, leading to uninterrupted deployment pipelines
        \item Deployed \textbf{300+} bi-weekly microservice releases, tracked via \textbf{JIRA}, through \textbf{Chef} configuration management and custom deployment scripts, accelerating delivery of new UI and backend features
    \end{itemize}

\end{experienceSection}

% --------- Projects -----------
\begin{experienceSection}{Projects}

    \projectItem[
        title=RAG Implementation for arXiv Papers,
        duration={Nov 2024},
    ]
    \begin{itemize}
        \vspace{-0.5em}
        \itemsep -6pt {}
        \item Devised a multimodal pipeline using \textbf{Python} to extract and vectorize content from \textbf{2000+} arXiv papers, implementing \textbf{CLIP} and text embedding models, \textbf{DynamoDB} indexing and vector database storage
        \item Implemented a similarity search and summarization pipeline with DynamoDB and GPT-4o mini to deliver concise, contextually relevant responses to user queries with an average response time of under \textbf{2 seconds}.
    \end{itemize}

    
    \projectItem[
        title=AWS-Based Face Recognition App,
        duration={May 2024},
    ]
    \begin{itemize}
        \vspace{-0.5em}
        \itemsep -6pt {}
        \item Created and deployed a scalable \textbf{Flask} web application using \textbf{Python} and \textbf{Gunicorn} on\textbf{ AWS EC2}, implementing HTTP-based image uploads through asynchronous processing pipeline leveraging \textbf{S3} storage and \textbf{SQS} message queuing
        \item Architected an \textbf{auto-scaling} infrastructure that dynamically scales up to 20 EC2 instances based on SQS queue depth metrics, ensuring optimal performance and cost-efficiency for real-time image processing under variable workloads
    \end{itemize}

    \projectItem[
        title=Kubernetes based Data Processing Pipeline,
        duration={Oct 2024},
    ]
    \begin{itemize}
        \vspace{-0.5em}
        \itemsep -6pt {}
        \item Built a highly scalable data processing pipeline using \textbf{Apache Kafka} and \textbf{Neo4j} that processes \textbf{100,000+} NYC taxi records in near-real-time, reducing spatial analytics query time by \textbf{60\%} and enabling real-time traffic pattern identification.
        \item Tested the pipeline on \textbf{PageRank} and \textbf{BFS} algorithms on the resulting neo4j graph database, establishing individual and relative importance of locations. 


    \end{itemize}


\end{experienceSection}


\end{document}
