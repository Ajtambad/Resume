% Document class and font size
\documentclass[a4paper,9pt]{extarticle}

% Packages
\usepackage[utf8]{inputenc} % For input encoding
\usepackage{geometry} % For page margins
\geometry{a4paper, margin=0.5in} % Set paper size and margins
\usepackage{titlesec} % For section title formatting
\usepackage{enumitem} % For itemized list formatting
\usepackage{hyperref} % For hyperlinks

% Formatting
\setlist{noitemsep} % Removes item separation
\titleformat{\section}{\large\bfseries}{\thesection}{1em}{}[\titlerule] % Section title format
\titlespacing*{\section}{0pt}{\baselineskip}{\baselineskip} % Section title spacing

% Begin document
\begin{document}

% Disable page numbers
\pagestyle{empty}

% Header
\begin{center}
\textbf{\huge Amogh Jagadish Tambad}\\[2pt] % Name
tambadamogh@gmail.com \hspace{1mm} $|$ \hspace{1mm} +1(480) 876-5096  \hspace{1mm} $|$ \hspace{1mm} $linkedin.com/in/ajtambad/$ \hspace{1mm} $|$ \hspace{1mm} $github.com/Ajtambad$
\end{center}

% Education Section
\section*{EDUCATION}
\noindent
\textbf{Master of Science}, Computer Science \hfill May 2025 \\ % University name and location
\textit{Arizona State University, Tempe, Arizona}
\hfill GPA: 3.96/4\\ % Degree and GPA
\textbf{Relevant Coursework:} Cloud Computing, Data Processing at Scale, Data Mining, Data Visualization\\

\noindent
\textbf{Bachelor of Technology (B.Tech)}, Computer Science and Engineering \hfill May 2021 \\ % University name and location
\textit{REVA University, Bangalore, India}
\hfill GPA: 8.93/10\\ % Degree and GPA
\textbf{Relevant Coursework:} Data Structures and Algorithms, Computer Architecture, Operating Systems.

% Skills Section
\section*{SKILLS}
\begin{itemize}
    \item \textbf{Languages:} Python, C++, Bash, C, SQL, Scala, HTML, Java, JavaScript, Groovy. % Programming skills
    \item \textbf{Tools and Technologies:} AWS (EC2, ECR, SQS, S3, Lambda, SNS), Git, Jenkins, Kafka, Spark, Heroku, Azure, Splunk, Zabbix, Docker, Kubernetes, PostgreSQL, MongoDB, GitHub Actions, Cribl, OpenShift. % Software skills
    \item \textbf{Libraries and Frameworks:} PyTorch, TensorFlow, Flask, OpenCV, Pandas, Keras, scikit-learn, Nginx, React, Node,js.
\end{itemize}

% Experience Section
\section*{EXPERIENCE}
\noindent
\textbf{IT-Infrastructure-Platform/SRE Intern}
\hfill Jun 2024 - Aug 2024\\ % Position and duration
\textit{Arch Mortgage Insurance, Greensboro, North Carolina}
\begin{itemize}
    \item Filtered logs and events going from OpenShift Kubernetes Clusters to \textbf{Splunk} using \textbf{Cribl} stream pipelines, reducing Splunk storage utilization by \textbf{40-50 GB/day} with \textbf{20\%} increase in search time.
    \item Designed a \textbf{groovy} script to eliminate \textbf{Jenkins GUI} access from the command line, preventing unauthorized access.
    \item Worked with \textbf{OpenShift} to manage container-based applications in the \textbf{Kubernetes} environment.
    

\end{itemize}

\noindent
\textbf{System Engineer - 1}
\hfill May 2021 - Jul 2023\\ % Position and duration
\textit{Oracle Cerner, Bengaluru, India}
\begin{itemize}
    \item Engaged with the software development team on \textbf{Splunk} upgrades, troubleshooting, and deployments, ensuring up-to-date servers.
    \item Migrated 80\% data from On-prem to \textbf{AWS}, making access to data more flexible, secure, and inexpensive.
    \item Integrated \textbf{Jenkins} and \textbf{GitHub} to maintain important documentation and test merge requests for semantic errors, reducing 1-2 hours per week of manual labour.
    \item Managed \textbf{CI/CD} pipelines to automate and oversee 300+ bi-weekly microservice deployments for web applications, enabling rapid delivery of new UI and backend features.
    \item Managed over 10 projects and 400+ tasks to completion through \textbf{JIRA}, resulting in smooth and error-free delivery. 
\end{itemize}



% Projects Section
\section*{PROJECTS}

\noindent
\textbf{RAG Implementation for arXiv Papers} \hfill Oct 2024 - Nov 2024\\% Project link and duration
\textit{Arizona State University, Tempe, Arizona}
\begin{itemize}
    
    \item Extracted tables, images, equations, and text from \textbf{2000+} arXiv papers for vectorization and storage.
    \item Vectorized and stored them in separate vector stores using models like \textbf{CLIP} and text embedding models.
    \item Implemented \textbf{similarity search} to retrieve the top 'k' relevant text and image chunks from \textbf{DynamoDB}.
    \item Summarized retrieved content using the \textbf{OpenAI GPT-4o mini} model, delivering concise, contextually relevant responses to user queries.
\end{itemize}

\noindent
\textbf{AWS Based Live Face Recognition App}  \hfill Feb 2024 - May 2024\\ % Project name and location
\textit{Arizona State University, Tempe, Arizona} % Project link and duration
\begin{itemize}
    \item Built a web application using \textbf{Flask API} and \textbf{Gunicorn} server that takes image files as input, performs image recognition, and outputs predictions.
    \item Created web tier using AWS \textbf{EC2} instance that receives images via \textbf{HTTP POST} requests and forwards them to AWS \textbf{SQS}.
    \item Designed an \textbf{auto-scaling} app tier that spawns up to \textbf{20} EC2 instances based on the number of requests in SQS with each of the instances performing image recognition.
    \item Stored the predictions in \textbf{S3} buckets and sent them back through the web-tier, keeping the overall latency at under \textbf{3 minutes} for \textbf{50} concurrent requests.
    
\end{itemize}

\noindent
\textbf{Kubernetes based Data Processing Pipeline}  \hfill Oct 2024 - Nov 2024\\ % Project name and location
\textit{Arizona State University, Tempe, Arizona} % Project link and duration
\begin{itemize}
    \item Built a highly scalable and available data processing pipeline that allows near-real-time processing and \textbf{analytics} of NYC Taxi Rides based spatial document stream data.
    \item Managed \textbf{Kubernetes} deployments of \textbf{Kafka}, \textbf{Zookeeper}, \textbf{Kafka-Connect}, and \textbf{Neo4j} components.
    \item Tested the pipeline using a document stream as input and performed \textbf{PageRank} and \textbf{BFS} algorithms on the resulting neo4j graph database, establishing individual and relative importance of locations. 
    
\end{itemize}


% End document
\end{document}
